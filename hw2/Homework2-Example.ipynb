{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework2_Example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "066689ab78894d4683af03f8ccde7c1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e2787bdcdf14becb55e4ebf7e88afa0",
              "IPY_MODEL_8903cd238aee40c590b99303a56b1ee7",
              "IPY_MODEL_16ada3afc0f04812b375eed1c0558f9f"
            ],
            "layout": "IPY_MODEL_32f47c04a8a14b43bfa2fcaeef86c007"
          }
        },
        "3e2787bdcdf14becb55e4ebf7e88afa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72c66505a64544cba9a751430ad54d22",
            "placeholder": "​",
            "style": "IPY_MODEL_68d4667753174c24a094b4be2dbe0f7e",
            "value": "100%"
          }
        },
        "8903cd238aee40c590b99303a56b1ee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0a587e93eac4887abbb62d7e50dad61",
            "max": 5241,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfd61d949101465993d3a1a596587022",
            "value": 5241
          }
        },
        "16ada3afc0f04812b375eed1c0558f9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e633add3e4f4eed93362b11dc76fd2a",
            "placeholder": "​",
            "style": "IPY_MODEL_c19cb448eb8547c4bb23ed7df73863e4",
            "value": " 5241/5241 [01:43&lt;00:00, 57.85it/s]"
          }
        },
        "32f47c04a8a14b43bfa2fcaeef86c007": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72c66505a64544cba9a751430ad54d22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68d4667753174c24a094b4be2dbe0f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0a587e93eac4887abbb62d7e50dad61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfd61d949101465993d3a1a596587022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e633add3e4f4eed93362b11dc76fd2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c19cb448eb8547c4bb23ed7df73863e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Convolution Neural Network Homework2\n",
        "\n",
        "In this homework, we are going to practice:\n",
        "1. How to preprocess and load data in pytorch\n",
        "2. How to build a CNN model for training\n",
        "3. Training/Validation Process and plot the result.\n",
        "4. Using pretrained model.\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://miro.medium.com/max/895/1*RjZe7cfnhdRhhLimLvapow.png\" width=\"800\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "tcFAjfy2BNnG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.1 Preparation"
      ],
      "metadata": {
        "id": "ld4bNcT3u3yo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5a0t1vX_toU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c4b01a-1b49-4283-f8cb-989cd8d26b92"
      },
      "source": [
        "import os\n",
        "import csv\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch.nn as nn\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Use device:\",device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UBUxdgl-THIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MHZYBJkQWRZ"
      },
      "source": [
        "##############################################\n",
        "# Decide your work and save path\n",
        "##############################################\n",
        "DataPath = '/content/homework2/'\n",
        "SavePath = '/content/drive/MyDrive/Colab Notebooks/homework2/'\n",
        "\n",
        "os.makedirs(DataPath, exist_ok = True)\n",
        "os.makedirs(SavePath, exist_ok = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_nJ97y2JXsn"
      },
      "source": [
        "## 0.2 Download DataSet: 10 class creature dataset\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://www.mirrormedia.com.tw/assets/images/20210811183042-492063c52c4c70e0ffe94db30f8395b8-mobile.jpg\" width=\"400\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method 1: using origin gdown to download the id file"
      ],
      "metadata": {
        "id": "Q145CtRrXPhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isdir(os.path.join(DataPath, 'train_dataset/')):\n",
        "    !pip install --upgrade --no-cache-dir gdown\n",
        "    !gdown --id 1HguaSxM4tMCGU0VjmWW0cCzf3EhoaOWr --output 'dataset.zip'\n",
        "    !unzip -q dataset.zip -d '/content/homework2' # the -d should be the same as DataPath\n",
        "\n",
        "else:\n",
        "    print(\"File already exists.\")"
      ],
      "metadata": {
        "id": "uHVmaBxlLzBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method2: Download from link to unzip\n",
        "\n",
        "1. Download File from the link: https://drive.google.com/uc?id=1HguaSxM4tMCGU0VjmWW0cCzf3EhoaOWr \n",
        "2. Upload to your google drive\n",
        "3. Your path way of the zip : `'./drive/MyDrive/[where you put in your drive])`\n",
        "3. unzip to your current workplace"
      ],
      "metadata": {
        "id": "g_1Xp4GNIjIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# There is a space between 'homework2_Dataset' and '.zip'\n",
        "# -q: quiet mode\n",
        "# -d: should be the same as DataPath\n",
        "!unzip -q './drive/MyDrive/homework2_Dataset .zip' -d '/content/homework2'"
      ],
      "metadata": {
        "id": "fQenrGrTIiPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOwWp6phJxUr"
      },
      "source": [
        "# 1 Data Preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vbSNxQJgu-c"
      },
      "source": [
        "## 1.1 Check on homework2 data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gsa5EGSVASI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "b3f5e26e-5dd3-4bd6-b9b1-5a93df2f7790"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(os.path.join(DataPath, 'train.csv'))\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          img  label\n",
              "count   20938  20938\n",
              "unique  20938     10\n",
              "top     0.jpg    dog\n",
              "freq        1   3890"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f8a5289-ead5-45c9-b997-39a2d45d8f11\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>20938</td>\n",
              "      <td>20938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>20938</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>0.jpg</td>\n",
              "      <td>dog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>3890</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f8a5289-ead5-45c9-b997-39a2d45d8f11')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f8a5289-ead5-45c9-b997-39a2d45d8f11 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f8a5289-ead5-45c9-b997-39a2d45d8f11');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir('/content/hw2_ex/train_dataset')))\n",
        "print(len(os.listdir('/content/hw2_ex/test_dataset')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_w8BpiT6QoY",
        "outputId": "677242ca-141b-46b8-fcb4-5e7cabc6cabd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20938\n",
            "5241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzUDroffU_rU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "421ee11d-aee1-4b51-ad73-b365a775370f"
      },
      "source": [
        "print(df['label'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['butterfly', 'cat', 'chicken', 'cow', 'dog', 'elephant', 'horse', 'sheep', 'spider', 'squirrel']\n",
            "\n",
            "dog          3890\n",
            "spider       3856\n",
            "chicken      2478\n",
            "horse        2098\n",
            "butterfly    1689\n",
            "cow          1492\n",
            "squirrel     1489\n",
            "sheep        1456\n",
            "cat          1334\n",
            "elephant     1156\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(df['label'].value_counts().index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY-nB4QAHFh1",
        "outputId": "c3974bfa-ad01-4f42-864a-0e3acdf71a65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['butterfly',\n",
              " 'cat',\n",
              " 'chicken',\n",
              " 'cow',\n",
              " 'dog',\n",
              " 'elephant',\n",
              " 'horse',\n",
              " 'sheep',\n",
              " 'spider',\n",
              " 'squirrel']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Class = {}\n",
        "idx = 0\n",
        "for label in sorted(df['label'].value_counts().index):\n",
        "  Class[label] = idx\n",
        "  idx += 1\n",
        "Class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrJuzKy6GuZo",
        "outputId": "08832dab-c13e-4af2-8208-60d352e50575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'butterfly': 0,\n",
              " 'cat': 1,\n",
              " 'chicken': 2,\n",
              " 'cow': 3,\n",
              " 'dog': 4,\n",
              " 'elephant': 5,\n",
              " 'horse': 6,\n",
              " 'sheep': 7,\n",
              " 'spider': 8,\n",
              " 'squirrel': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23_htZkLhMV8"
      },
      "source": [
        "## 1.2 Pytorch Dataset & Dataloaders"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.1 torchvision.transforms *"
      ],
      "metadata": {
        "id": "l8qdad2SkFx1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zHStfuBaKNJ"
      },
      "source": [
        "##############################################\n",
        "# Image preprocess and data augmentation\n",
        "#\n",
        "# Hint:\n",
        "#   Resize input image first\n",
        "#   you need to change image to tensor\n",
        "#   Augmentation on train but not valid/test\n",
        "##############################################\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    # To Do\n",
        "    ])\n",
        "valid_transform = transforms.Compose([\n",
        "    # To Do\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.2 torch.utils.data.Dataset *"
      ],
      "metadata": {
        "id": "zzZ0sJ_1BTwp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ohR6Ch4TN4I"
      },
      "source": [
        "##############################################\n",
        "# Add dataset\n",
        "##############################################\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class dataset(Dataset):\n",
        "    def __init__(self, imgpath, csvpath, transform = valid_transform):\n",
        "        # --------------------------------------------\n",
        "        # Initialize paths, transforms, and so on\n",
        "        # --------------------------------------------\n",
        "        pass\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        # --------------------------------------------\n",
        "        # 1. Read from file (using numpy.fromfile, PIL.Image.open)\n",
        "        # 2. Preprocess the data (torchvision.Transform).\n",
        "        # 3. Return the data (e.g. image and label)\n",
        "        # --------------------------------------------\n",
        "        pass\n",
        "        \n",
        "    def __len__(self):\n",
        "        # --------------------------------------------\n",
        "        # Indicate the total size of the dataset\n",
        "        # --------------------------------------------\n",
        "        pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY8h9sALfSpi"
      },
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "imgpath = os.path.join(DataPath, 'train_dataset/')\n",
        "csvpath = os.path.join(DataPath, 'train.csv')\n",
        "\n",
        "trainset = dataset(imgpath, csvpath)\n",
        "train_set_size = int(len(trainset) * 0.7)\n",
        "valid_set_size = int(len(trainset) * 0.15)\n",
        "test_set_size = len(trainset) - train_set_size - valid_set_size\n",
        "\n",
        "trainset, validset, testset = random_split(trainset, [train_set_size, valid_set_size, test_set_size])\n",
        "\n",
        "trainset.transform = train_transform\n",
        "validset.transform = valid_transform\n",
        "testset.transform = valid_transform\n",
        "\n",
        "print(f'trainset: {len(trainset)}\\nvalidset: {len(validset)}\\ntestset: {len(testset)}')\n",
        "\n",
        "idx = np.random.randint(len(trainset))\n",
        "print(f'{idx:5d}/{len(trainset)} : {trainset[idx]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.3 torch.utils.data.DataLoader *"
      ],
      "metadata": {
        "id": "Oa8YpgKkBeS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loaded Datasets to DataLoaders\n",
        "\n",
        "# batch_size also affect training step.\n",
        "# higher: faster, stable\n",
        "#   but inprecise on optimize, may use large memory\n",
        "batch_size = 64\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers = 2)\n",
        "validloader = DataLoader(validset, batch_size=batch_size, shuffle=False, num_workers = 2)\n",
        "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers = 2)"
      ],
      "metadata": {
        "id": "SKQaTsC4x7Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Training module"
      ],
      "metadata": {
        "id": "BDXcqsa-vv6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def train(model, trainloader, optimizer, criterion):\n",
        "    # keep track of training loss\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    \n",
        "    # train the model \n",
        "    model.train()\n",
        "    for data, target in tqdm(trainloader):\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        # update training Accuracy\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        train_correct += (predicted == target).sum().item()\n",
        "\n",
        "    return train_loss/len(trainloader.dataset), train_correct/len(trainloader.dataset)"
      ],
      "metadata": {
        "id": "a_Tl-as8c5k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test(model, testloader, criterion):\n",
        "    # keep track of validation loss\n",
        "    valid_loss = 0.0\n",
        "    valid_correct = 0\n",
        "\n",
        "    # evaluate the model \n",
        "    model.eval()\n",
        "    for data, target in tqdm(testloader):\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average validation loss \n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "        # update validation Accuracy\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        valid_correct += (predicted == target).sum().item()\n",
        "\n",
        "    return valid_loss/len(testloader.dataset), valid_correct/len(testloader.dataset)"
      ],
      "metadata": {
        "id": "FzlwQDzUvoG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def modeltrain(model, trainloader, validloader, testloader, optimizer, criterion, epochs, save_model_path, earlystop=4):\n",
        "    history = {\n",
        "        'trainloss' : [],\n",
        "        'trainacc' : [],\n",
        "        'validloss' : [],\n",
        "        'validacc' : [],\n",
        "    }\n",
        "    state = {\n",
        "        'epoch' : 0,\n",
        "        'state_dict' : model.state_dict(),\n",
        "        'trainloss' : 10000,\n",
        "        'trainacc' : 0,\n",
        "        'validloss' : 10000,\n",
        "        'validacc' : 0,\n",
        "    }\n",
        "    valid_loss_min = 10000\n",
        "    trigger = 0\n",
        "    for epoch in range(epochs):\n",
        "        print(f'running epoch: {epoch+1}')\n",
        "        trainloss, trainacc = train(model, trainloader, optimizer, criterion)\n",
        "        validloss, validacc = test(model, validloader, criterion)\n",
        "\n",
        "        # print training/validation statistics \n",
        "        history['trainloss'].append(trainloss)\n",
        "        history['trainacc'].append(trainacc)\n",
        "        history['validloss'].append(validloss)\n",
        "        history['validacc'].append(validacc)\n",
        "        print(f'Training Loss  : {trainloss:.4f}\\t\\tTraining Accuracy  : {trainacc:.4f}')\n",
        "        print(f'Validation Loss: {validloss:.4f}\\t\\tValidation Accuracy: {validacc:.4f}')\n",
        "        \n",
        "        # save model if validation loss has decreased\n",
        "        if validloss <= valid_loss_min:\n",
        "            print(f'Validation loss decreased ({valid_loss_min:.4f} --> {validloss:.4f}).  Saving model ...\\n')\n",
        "            state['epoch'] = epoch\n",
        "            state['state_dict'] = model.state_dict()\n",
        "            state['trainloss'] = trainloss\n",
        "            state['trainacc'] = trainacc\n",
        "            state['validloss'] = validloss\n",
        "            state['validacc'] = validacc\n",
        "\n",
        "            torch.save(state, save_model_path)\n",
        "            valid_loss_min = validloss\n",
        "            trigger = 0\n",
        "        # if model dont improve for 5 times, interupt.\n",
        "        else:\n",
        "            trigger += 1\n",
        "            print(f'Validation loss increased ({valid_loss_min:.4f} --> {validloss:.4f}). Trigger {trigger}/{earlystop}\\n')\n",
        "            if trigger == earlystop:\n",
        "                break\n",
        "    print('\\nTest Evaluate:')\n",
        "    testloss, testacc = test(model, testloader, criterion)\n",
        "    state['testloss'] = testloss\n",
        "    state['testacc'] = testacc\n",
        "    torch.save(state, save_model_path)\n",
        "    bestepoch = state['epoch']\n",
        "    validloss = state['validloss']\n",
        "    validacc = state['validacc']\n",
        "    print(f'Best model on epoch : {bestepoch}/{epoch}')\n",
        "    print(f'validation loss: {validloss:.4f}\\t\\t validation acc : {validacc:.4f}')\n",
        "    print(f'test loss      : {testloss:.4f}\\t\\t test acc \\t: {testacc:.4f}')\n",
        "    return history"
      ],
      "metadata": {
        "id": "kYGZ-S5rcOnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP8kFu3mWmJo"
      },
      "source": [
        "# 3 CNN Model Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SavePathModel = os.path.join(SavePath, 'model_exp')\n",
        "os.makedirs(SavePathModel, exist_ok=True)"
      ],
      "metadata": {
        "id": "mRkMeQXHwDtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Build Better Network? *\n",
        "\n",
        "### Layer\n",
        "- Adjustment of convolution/pooling layer\n",
        "- [Activation Layer](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)\n",
        "- Global [Average](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html#torch.nn.AdaptiveAvgPool2d)/[Max](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool2d.html#torch.nn.AdaptiveMaxPool2d) Pooling\n",
        "\n",
        "### Training Robustness\n",
        "- [Augmentation](https://pytorch.org/vision/stable/transforms.html)\n",
        "- [Batch Normalization](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d)\n",
        "- [Dropout Layers](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout)"
      ],
      "metadata": {
        "id": "7sjLe7FiN08I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################\n",
        "# Build your model here!\n",
        "# \n",
        "# Practice:\n",
        "#   Improve your own Model!\n",
        "##############################################\n",
        "\n",
        "class trainmodel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(trainmodel, self).__init__()\n",
        "        # To Do\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        # To Do\n",
        "        pass\n",
        "\n",
        "model = trainmodel()\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "zfZ5rUygNfQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Set Hyperparameter *\n",
        "### Optimizer: attempt to find global minimum\n",
        "- [SGD with momentum](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)\n",
        "- [ADAM](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam)\n",
        "- [torch.optim](https://pytorch.org/docs/stable/optim.html)\n",
        "\n",
        "### Learning Rate Sceduler\n",
        "- [Cosine Annealing Learning Rate](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingLR.html#torch.optim.lr_scheduler.CosineAnnealingLR)"
      ],
      "metadata": {
        "id": "_agoKu-WnkGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################\n",
        "# Set Hyperparameter\n",
        "# \n",
        "# Hint:\n",
        "#   you can try different criterion loss, optimizer\n",
        "##############################################\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "n_epochs = 2\n",
        "save_model_path = os.path.join(SavePathModel, 'model_weight.pth')"
      ],
      "metadata": {
        "id": "AWL52mgPmXdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Start Training!"
      ],
      "metadata": {
        "id": "QpnDkiZ8v2KZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sIruMAzZD43"
      },
      "source": [
        "history = modeltrain(\n",
        "        model = model,\n",
        "        trainloader = trainloader,\n",
        "        validloader = validloader,\n",
        "        testloader = testloader,\n",
        "        optimizer = optimizer,\n",
        "        criterion = criterion,\n",
        "        epochs = n_epochs,\n",
        "        save_model_path = save_model_path\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 Plot the result"
      ],
      "metadata": {
        "id": "K3c1wH-SwEOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "save_history = json.dumps(history)\n",
        "with open(os.path.join(SavePathModel, 'history.json'), 'w') as f:\n",
        "    json.dump(save_history, f)"
      ],
      "metadata": {
        "id": "-S0juEEhHKhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot(name, savedir, trainhistory, validhistory):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(trainhistory, label = 'train')\n",
        "    plt.plot(validhistory,  label = 'valid')\n",
        "    plt.title(name)\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.show()\n",
        "    plt.savefig(savedir)"
      ],
      "metadata": {
        "id": "KuEqmcn3wJf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot('Training Loss', os.path.join(SavePathModel,'loss.png'), history['trainloss'], history['validloss'])"
      ],
      "metadata": {
        "id": "1_e8wpHHxwsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot('Training Accuracy', os.path.join(SavePathModel,'acc.png'), history['trainacc'], history['validacc'])"
      ],
      "metadata": {
        "id": "eyXjiIvjxugt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYnZ7X1QytAw"
      },
      "source": [
        "## 3.5 load weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d25c8cb-7c76-4143-c098-0e5b764d5df1",
        "id": "oXzMVqcRytA3"
      },
      "source": [
        "## create model as same as your training \n",
        "model = trainmodel()\n",
        "model.to(device)\n",
        "\n",
        "## load weight\n",
        "state = torch.load(save_model_path)\n",
        "model.load_state_dict(state['state_dict'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh9jgy4mytA3"
      },
      "source": [
        "## 3.6 test and save result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpnGYTnKytA3"
      },
      "source": [
        "# If needed, Edit to make fit your situation\n",
        "\n",
        "transform = transforms.Compose([\n",
        "       transforms.Resize((224, 224)),\n",
        "       transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "class test_set(Dataset):\n",
        "    def __init__(self, img_path, csv_path, transform = transform):\n",
        "        # --------------------------------------------\n",
        "        # Initialize paths, transforms, and so on\n",
        "        # --------------------------------------------\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        self.img_path = img_path\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        # --------------------------------------------\n",
        "        # 1. Read from file (using numpy.fromfile, PIL.Image.open)\n",
        "        # 2. Preprocess the data (torchvision.Transform).\n",
        "        # 3. Return the data (e.g. image and label)\n",
        "        # --------------------------------------------\n",
        "        imgpath = os.path.join(self.img_path, self.df.iloc[index, 0])\n",
        "        img = Image.open(imgpath)\n",
        "        img = self.transform(img)\n",
        "\n",
        "        return img, index\n",
        "        \n",
        "    def __len__(self):\n",
        "        # --------------------------------------------\n",
        "        # Indicate the total size of the dataset\n",
        "        # --------------------------------------------\n",
        "        return len(self.df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYIzN0z8ytA4"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "#load test data\n",
        "testing_path = os.path.join(DataPath, 'test_dataset')\n",
        "testcsv_path = os.path.join(DataPath, 'test.csv')\n",
        "\n",
        "df = pd.read_csv(testcsv_path)\n",
        "\n",
        "inv_Class = dict((v, k) for k, v in Class.items())\n",
        "\n",
        "print(len(df))\n",
        "\n",
        "testset = test_set(testing_path, testcsv_path)\n",
        "testloader = DataLoader(testset, batch_size=1, shuffle=False,pin_memory=True,num_workers = 2)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for data, idx in tqdm(testloader):\n",
        "        data = data.to(device)\n",
        "        pred = F.softmax(model(data),dim=1)\n",
        "        pred = np.argmax(pred.detach().cpu().numpy(),axis=1)\n",
        "\n",
        "        df.at[idx, 'label'] = inv_Class[int(pred)] # convert predicted integer back to class string, only works when batch = 1\n",
        "\n",
        "df.head()\n",
        "df.to_csv(os.path.join(SavePathModel, 'test_model.csv'), encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Pretrained Model Finetune\n",
        "\n",
        "[Transfer Learning](https://hackmd.io/@allen108108/H1MFrV9WH)\n",
        "\n",
        "[Transfer learning for computer vision tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
        "\n",
        "[Models and pre-trained weights](https://pytorch.org/vision/stable/models.html)\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://miro.medium.com/max/1400/1*Ww3AMxZeoiB84GVSRBr4Bw.png\" width=\"700\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "GLbkFjNYn-Fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SavePathPretrain = os.path.join(SavePath, 'pretrain_exp')\n",
        "os.makedirs(SavePathPretrain, exist_ok=True)"
      ],
      "metadata": {
        "id": "qcQmDmq4yGLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Call Pretrained weight *\n",
        "\n",
        "**WARNINGS** Maybe Freeze some layer would be good for finetune\n",
        "> [Which layers should I freeze for fine tuning a resnet model on keras?](https://stackoverflow.com/questions/47206714/which-layers-should-i-freeze-for-fine-tuning-a-resnet-model-on-keras)\n",
        ">\n",
        "> [How the pytorch freeze network in some layers, only the rest of the training?](https://discuss.pytorch.org/t/how-the-pytorch-freeze-network-in-some-layers-only-the-rest-of-the-training/7088)"
      ],
      "metadata": {
        "id": "ARnkT6a4o4OI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################\n",
        "# Set Pretrained model for finetune\n",
        "# \n",
        "# Hint:\n",
        "#   you can try different model!\n",
        "#   resnet18 is just an example\n",
        "#   \n",
        "#   Remember to change the output size to match our trainingset label\n",
        "#\n",
        "#   If neccesary, freeze some layer\n",
        "##############################################\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "# resnet18 as example\n",
        "finetune_model = models.resnet18(pretrained=True).to(device)\n",
        "\n",
        "# Remember to change the output size to match our trainingset label\n",
        "# Hint: Print out the model and assign new size to the model output.\n",
        "# To Do"
      ],
      "metadata": {
        "id": "-Q09uqgZoZCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Set Hyperparameter *\n",
        "### Optimizer: attempt to find global minimum\n",
        "- [SGD with momentum](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)\n",
        "- [ADAM](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam)\n",
        "- [torch.optim](https://pytorch.org/docs/stable/optim.html)\n",
        "\n",
        "### Learning Rate Sceduler\n",
        "- [Cosine Annealing Learning Rate](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingLR.html#torch.optim.lr_scheduler.CosineAnnealingLR)"
      ],
      "metadata": {
        "id": "zFFF5jEWvSJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################\n",
        "# Set Hyperparameter\n",
        "# \n",
        "# Hint:\n",
        "#   you can try different criterion loss, optimizer\n",
        "##############################################\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=finetune_model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "n_epochs = 1\n",
        "save_fintune_path = os.path.join(SavePathPretrain, 'model_weight.pth')"
      ],
      "metadata": {
        "id": "-ALjxb-eqhCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Training Process"
      ],
      "metadata": {
        "id": "peXW1HpGqbQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_fintune = modeltrain(\n",
        "        model = finetune_model,\n",
        "        trainloader = trainloader,\n",
        "        validloader = validloader,\n",
        "        testloader = testloader,\n",
        "        optimizer = optimizer,\n",
        "        criterion = criterion,\n",
        "        epochs = n_epochs,\n",
        "        save_model_path = save_fintune_path\n",
        "        )"
      ],
      "metadata": {
        "id": "Urf7tynnq4jT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 Plot the result"
      ],
      "metadata": {
        "id": "6viyqofxrWcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "save_history = json.dumps(history_fintune)\n",
        "with open(os.path.join(SavePathPretrain, 'history_fintuned.json'), 'w') as f:\n",
        "    json.dump(save_history, f)"
      ],
      "metadata": {
        "id": "upumvR-trQRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot('Training Loss', os.path.join(SavePathPretrain,'loss.png'), history_fintune['trainloss'], history_fintune['validloss'])"
      ],
      "metadata": {
        "id": "1EEGhCIurQRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot('Training Accuracy', os.path.join(SavePathPretrain,'acc.png'), history_fintune['trainacc'], history_fintune['validacc'])"
      ],
      "metadata": {
        "id": "Tg9dtQs7rQRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXAmOe_Bzr7O"
      },
      "source": [
        "## 4.5 load weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e3f93fa-1551-4756-a4e8-491bc7edb81c",
        "id": "TyVjPjXCzr7d"
      },
      "source": [
        "## Should be the same as your pretrained model type\n",
        "finetune_model = models.resnet18(pretrained=False)\n",
        "finetune_model.to(device)\n",
        "\n",
        "## load weight\n",
        "state = torch.load(save_fintune_path)\n",
        "finetune_model.load_state_dict(state['state_dict'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU9Loa5ezr7e"
      },
      "source": [
        "## 4.6 test and save result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECYAzwTGzr7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "066689ab78894d4683af03f8ccde7c1a",
            "3e2787bdcdf14becb55e4ebf7e88afa0",
            "8903cd238aee40c590b99303a56b1ee7",
            "16ada3afc0f04812b375eed1c0558f9f",
            "32f47c04a8a14b43bfa2fcaeef86c007",
            "72c66505a64544cba9a751430ad54d22",
            "68d4667753174c24a094b4be2dbe0f7e",
            "b0a587e93eac4887abbb62d7e50dad61",
            "cfd61d949101465993d3a1a596587022",
            "0e633add3e4f4eed93362b11dc76fd2a",
            "c19cb448eb8547c4bb23ed7df73863e4"
          ]
        },
        "outputId": "71601109-fa26-4db8-f47d-4d045ab83235"
      },
      "source": [
        "#load test data\n",
        "testing_path = os.path.join(DataPath, 'test_dataset')\n",
        "testcsv_path = os.path.join(DataPath, 'test.csv')\n",
        "\n",
        "df = pd.read_csv(testcsv_path)\n",
        "\n",
        "inv_Class = dict((v, k) for k, v in Class.items())\n",
        "\n",
        "print(len(df))\n",
        "\n",
        "testset = test_set(testing_path, testcsv_path)\n",
        "testloader = DataLoader(testset, batch_size=1, shuffle=False,pin_memory=True,num_workers = 2)\n",
        "\n",
        "finetune_model.eval()\n",
        "with torch.no_grad():\n",
        "    for data, idx in tqdm(testloader):\n",
        "        data = data.to(device)\n",
        "        pred = F.softmax(finetune_model(data),dim=1)\n",
        "        pred = np.argmax(pred.detach().cpu().numpy(),axis=1)\n",
        "\n",
        "        df.at[idx, 'label'] = inv_Class[int(pred)] # convert predicted integer back to class string, only works when batch = 1\n",
        "\n",
        "df.head()\n",
        "df.to_csv(os.path.join(SavePathPretrain, 'test_pretrain.csv'), encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5241\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5241 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "066689ab78894d4683af03f8ccde7c1a"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}
